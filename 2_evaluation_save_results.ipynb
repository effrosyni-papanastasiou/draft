{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "from scipy.optimize import linprog\n",
    "import time\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = 500000\n",
    "random.seed(10)\n",
    "dataset = 'russian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load episode set $E$ with the users that retweeted each original tweet in the trace. \n",
    "\n",
    "Each episode $E_{s}$ includes the users that retweeted s, ordered chronologically, as they appear in the trace. The first user in each episode is the user that originally tweeted the tweet, and is denoted by $r_{s}$. Subsequent users in $E_{s}$ are users that retweeted s, either directly from user $r_{s}$ or from another user that appears in Es before them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pickle.load(open(\"./Extracted/\"+dataset+\"/D\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = pickle.load(open(\"./Extracted/\"+dataset+\"/E\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in E:\n",
    "    E[tweet] = list(dict.fromkeys(E[tweet]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the set of original tweets denoted by $S$. \n",
    "\n",
    "The set of original tweets is denoted by $S$, where $S$ = S is the total number of original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pickle.load(open(\"./Extracted/\"+dataset+\"/S\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $U$ set xith unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = pickle.load(open(\"./Extracted/\"+dataset+\"/U\"+ str(lines) + \".p\", \"rb\"))\n",
    "U = list(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $M_{ij}$ variables that count number of episodes where the ordered pair (i,j) appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pickle.load(open(\"./Extracted/\"+dataset+\"/M_d\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $Q_{ij}$ results for the ordered pair (i,j) derived from the consrained algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = pickle.load(open(\"./Extracted/\"+dataset+\"/results/Q_constrained_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $s_{ij}$ derived from the consrained algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.load(open(\"./Extracted/\"+dataset+\"/results/s_constrained_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $k_{ij}$ derived from Saito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pickle.load(open(\"./Extracted/\"+dataset+\"/results/k_saito_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $Q_{ij}$ derived from Newman's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_newman = pickle.load(open(\"./Extracted/\"+dataset+\"/results/Q_newman_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(obj):\n",
    "    if type(obj) == list:\n",
    "        return [l for L in obj for l in L]\n",
    "    if type(obj) == dict:\n",
    "        return [l for i in obj for l in obj[i].values()]\n",
    "    if type(obj) == defaultdict:\n",
    "        return [l for i in obj for l in obj[i].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_serpent_graph(U,D):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "    for tweet in D:\n",
    "        for time in D[tweet]:\n",
    "            ind = list(D[tweet].keys()).index(time)\n",
    "            if ind+1==len(D[tweet]): break\n",
    "            next_time = list(D[tweet].keys())[ind+1]\n",
    "            for u1 in D[tweet][time]:\n",
    "                for u2 in D[tweet][next_time]:\n",
    "                    G.add_edge(u1,u2)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_saito_graph(U,k):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "\n",
    "    for i in k:\n",
    "        for j in k[i]:\n",
    "            if k[i][j] > 0.5:\n",
    "                G.add_edge(i,j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_star_graph(U,E):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "    for s in E:\n",
    "        for j in E[s][1:]:\n",
    "            G.add_edge(E[s][0],j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_our_graph(U,Q):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "    for i in Q:\n",
    "        for j in Q[i]:\n",
    "            if Q[i][j] > 0.5:\n",
    "                G.add_edge(i,j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_newman_graph(U,Q):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "\n",
    "    for i in Q:\n",
    "        for j in Q[i]:\n",
    "            if Q[i][j] > 0.5:\n",
    "                G.add_edge(i,j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wedge_metric(graph):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    for i in graph.nodes:\n",
    "        leaders = set(graph.predecessors(i))\n",
    "        followers = set(graph.successors(i))\n",
    "        friends = leaders.intersection(followers)\n",
    "        if len(leaders) + len(followers) < 2:\n",
    "            continue\n",
    "        if leaders==followers and len(leaders)==1:\n",
    "            continue\n",
    "        L = len(leaders)\n",
    "        F = len(followers)\n",
    "        LintF = len(friends)\n",
    "        numerator += L*F - LintF\n",
    "        denominator += (L+F)**2 - L - F - 2*LintF\n",
    "\n",
    "    if denominator != 0:\n",
    "        result = 2 * numerator / denominator\n",
    "    else:\n",
    "        result = 0\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_check(E, Q):\n",
    "    '''\n",
    "    Function that checks feasibility of results\n",
    "\n",
    "    '''\n",
    "    retweets = 0 # minimum existing edges\n",
    "    infeasible_episodes = 0 \n",
    "    total_feasible_edges = []\n",
    "    total_inf = 0 \n",
    "    for s in E:\n",
    "        feasible_edges = 0 \n",
    "        for j in E[s]:\n",
    "            indx = E[s].index(j)\n",
    "            if indx!=0:\n",
    "                u_before = E[s][:indx]\n",
    "                for i in u_before: \n",
    "                    if i in Q and j in Q[i] and Q[i][j] > 0.5:\n",
    "                        feasible_edges +=1\n",
    "                        total_feasible_edges.append((i,j))\n",
    "\n",
    "        infeasible = (len(E[s]) - 1) - feasible_edges\n",
    "        if infeasible > 0:\n",
    "#             print('Tweet', s, 'retweeted by', len(E[s])-1, 'users in total. But, we only found:', feasible_edges, 'feasible edges, so the infeasible ones are:', infeasible)            \n",
    "            total_inf+=infeasible\n",
    "            infeasible_episodes+=1\n",
    "            \n",
    "        retweets += len(E[s])-1\n",
    "        total_feasible_edges = list(set(total_feasible_edges))\n",
    "        \n",
    "    return infeasible_episodes\n",
    "        \n",
    "#     print('Total feasbile edges:', len(total_feasible_edges), 'Number of retweets', retweets)\n",
    "#     print('Total infeasible edges:', total_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_path(E, U, Q, k, graph_type):\n",
    "    max_l = 0\n",
    "    max_path = 0\n",
    "    \n",
    "    if graph_type=='ours' or graph_type=='newman':    \n",
    "        for s in E:\n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(U)\n",
    "            for j in E[s][1:]:\n",
    "                    indx = E[s].index(j)\n",
    "                    u_before = E[s][:indx]\n",
    "                    for i in u_before: \n",
    "                            if j in Q[i] and Q[i][j] > 0.5:\n",
    "                                G.add_edge(i,j)\n",
    "\n",
    "            if len(nx.dag_longest_path(G))>max_l: \n",
    "                max_l = len(nx.dag_longest_path(G))\n",
    "                max_path = nx.dag_longest_path(G)\n",
    "                \n",
    "    if graph_type=='star':\n",
    "        for s in E:\n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(U)\n",
    "            for j in E[s][1:]:\n",
    "                G.add_edge(E[s][0],j)\n",
    "\n",
    "            if len(nx.dag_longest_path(G))>max_l: \n",
    "                max_l = len(nx.dag_longest_path(G))\n",
    "                max_path = nx.dag_longest_path(G)\n",
    "                \n",
    "    if graph_type=='saito':    \n",
    "        for s in E:\n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(U)\n",
    "            for j in E[s][1:]:\n",
    "                    indx = E[s].index(j)\n",
    "                    u_before = E[s][:indx]\n",
    "                    for i in u_before: \n",
    "                            if j in k[i] and k[i][j] > 0.5:\n",
    "                                G.add_edge(i,j)\n",
    "\n",
    "            if len(nx.dag_longest_path(G))>max_l: \n",
    "                max_l = len(nx.dag_longest_path(G))\n",
    "                max_path = nx.dag_longest_path(G)\n",
    "                \n",
    "    return max_l, max_path   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweetgraph(s, E, S, Q, k, pos, graph_type):\n",
    "        \n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        if graph_type=='ours' or graph_type=='newman':\n",
    "            t = 0\n",
    "            for j in E[s][1:]:\n",
    "                G.add_node(j)\n",
    "                indx = E[s].index(j)\n",
    "                u_before = E[s][:indx]\n",
    "                for i in u_before: \n",
    "                        G.add_node(i)\n",
    "                        if j in Q[i] and Q[i][j] > 0.5:\n",
    "                            G.add_edge(i,j, label=f'{t}')\n",
    "                            t+=1\n",
    "                            \n",
    "        elif graph_type=='star':\n",
    "            \n",
    "            G.add_node(E[s][0])\n",
    "            for j in E[s][1:]:\n",
    "                    G.add_edge(E[s][0],j)\n",
    "                    G.add_node(j)\n",
    "                    \n",
    "        elif graph_type=='saito':\n",
    "            t = 0\n",
    "            for j in E[s][1:]:\n",
    "                G.add_node(j)\n",
    "                indx = E[s].index(j)\n",
    "                u_before = E[s][:indx]\n",
    "                for i in u_before: \n",
    "                        G.add_node(i)\n",
    "                        if j in k[i] and k[i][j] > 0.5:\n",
    "                            G.add_edge(i,j, label=f'{t}')\n",
    "                            t+=1\n",
    "                            \n",
    "        elif graph_type=='serpent':\n",
    "            for time in D[s]:\n",
    "                ind = list(D[tweet].keys()).index(time)\n",
    "                if ind+1==len(D[tweet]): break\n",
    "                next_time = list(D[tweet].keys())[ind+1]\n",
    "                for u1 in D[tweet][time]:\n",
    "                    for u2 in D[tweet][next_time]:\n",
    "                        G.add_edge(u1,u2)\n",
    "\n",
    "        # print('- Edges:', G.edges)\n",
    "        color_map = []\n",
    "        cmap = plt.get_cmap('Greens')\n",
    "\n",
    "        for node in G:\n",
    "            if node == S[tweet]:\n",
    "                color_map.append('green')\n",
    "            else:\n",
    "                color_map.append('yellow')\n",
    "        \n",
    "        pos = nx.spring_layout(G)        \n",
    "        nx.draw_networkx_nodes(G, pos, node_color = color_map, cmap=plt.get_cmap('jet'), node_size = 300)\n",
    "        nx.draw_networkx_edges(G, pos, edge_color='r', arrows=True)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "        if graph_type=='ours' or graph_type=='saito':\n",
    "            nx.draw_networkx_edge_labels(G, pos, font_size=8)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "## 1. number of infeasible episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data['Graph Type with Lines: ' + str(lines)] = ['Ours','Saito','Star','Serpent', 'Newman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_ep_ours = f_check(E, Q)\n",
    "inf_ep_saito = f_check(E, k)\n",
    "inf_ep_newman = f_check(E, Q_newman)\n",
    "\n",
    "data['Infeasible Episodes'] = [inf_ep_ours, inf_ep_saito, 0, 0, inf_ep_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create graphs\n",
    "G_star = create_star_graph(U,E)\n",
    "G_ours = create_our_graph(U,Q)\n",
    "G_saito = create_saito_graph(U,k)\n",
    "G_newman = create_newman_graph(U,Q_newman)\n",
    "G_serpent = create_serpent_graph(U,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_ours = len(G_ours.edges())\n",
    "edges_saito = len(G_saito.edges())\n",
    "edges_star = len(G_star.edges())\n",
    "edges_serpent = len(G_serpent.edges())\n",
    "edges_newman = len(G_newman.edges())\n",
    "\n",
    "data['Number of edges'] = [edges_ours, edges_saito, edges_star, edges_serpent, edges_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Average out degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_ours = sum(d[1] for d in G_ours.out_degree())/float(len(G_ours))\n",
    "av_saito = sum(d[1] for d in G_saito.out_degree())/float(len(G_saito))\n",
    "av_star = sum(d[1] for d in G_star.out_degree())/float(len(G_star))\n",
    "av_serpent = sum(d[1] for d in G_serpent.out_degree())/float(len(G_serpent))\n",
    "av_newman = sum(d[1] for d in G_newman.out_degree())/float(len(G_newman))\n",
    "\n",
    "data['Average out degree'] = [av_ours, av_saito, av_star, av_serpent, av_newman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = list(G_ours.out_degree())\n",
    "max_degree_our = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_saito.out_degree())\n",
    "max_degree_saito = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_star.out_degree())\n",
    "max_degree_star = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_serpent.out_degree())\n",
    "max_degree_serpent = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_newman.out_degree())\n",
    "max_degree_newman = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "data['Max out degree'] = [max_degree_our, max_degree_saito, max_degree_star, max_degree_serpent, max_degree_newman]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = list(G_ours.in_degree())\n",
    "max_degree_our = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_saito.in_degree())\n",
    "max_degree_saito = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_star.in_degree())\n",
    "max_degree_star = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_serpent.in_degree())\n",
    "max_degree_serpent = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_newman.in_degree())\n",
    "max_degree_newman = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "data['Max in degree'] = [max_degree_our, max_degree_saito, max_degree_star, max_degree_serpent, max_degree_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Graph diameter\n",
    "\n",
    "The maximum among all the distances between a vertex to all other vertices is considered as the diameter of the Graph G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d89d7217090e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaxv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgd_ours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiameter_scc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_ours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ours'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mgd_saito\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiameter_scc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_saito\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Saito'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgd_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiameter_scc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Star'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d89d7217090e>\u001b[0m in \u001b[0;36mdiameter_scc\u001b[0;34m(G, graph_type)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# skip one nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmaxv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 \u001b[0mmaxv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaxv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/froso/.local/lib/python3.6/site-packages/networkx/algorithms/distance_measures.py\u001b[0m in \u001b[0;36mdiameter\u001b[0;34m(G, e, usebounds)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mextrema_bounding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"diameter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meccentricity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/froso/.local/lib/python3.6/site-packages/networkx/algorithms/distance_measures.py\u001b[0m in \u001b[0;36meccentricity\u001b[0;34m(G, v, sp)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbunch_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetworkx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_source_shortest_path_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/froso/.local/lib/python3.6/site-packages/networkx/algorithms/shortest_paths/unweighted.py\u001b[0m in \u001b[0;36msingle_source_shortest_path_length\u001b[0;34m(G, source, cutoff)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mnextlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_single_shortest_path_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnextlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/froso/.local/lib/python3.6/site-packages/networkx/algorithms/shortest_paths/unweighted.py\u001b[0m in \u001b[0;36m_single_shortest_path_length\u001b[0;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m  \u001b[0;31m# set the level of vertex v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mnextlevel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add neighbors of v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def diameter_scc(G, graph_type):\n",
    "    maxv = 0 \n",
    "    for C in nx.strongly_connected_components(G):\n",
    "        C = G.subgraph(C)\n",
    "        if len(C)>1: # skip one nodes\n",
    "            if nx.diameter(C)>maxv:\n",
    "                maxv=nx.diameter(C)\n",
    "    return maxv\n",
    "            \n",
    "gd_ours = diameter_scc(G_ours, 'Ours')\n",
    "gd_saito = diameter_scc(G_saito, 'Saito')\n",
    "gd_star = diameter_scc(G_star, 'Star')\n",
    "gd_serpent = diameter_scc(G_serpent, 'Serpent')\n",
    "gd_newman = diameter_scc(G_newman, 'Newman')\n",
    "\n",
    "data['Max graph diameter'] = [gd_ours, gd_saito, gd_star, gd_serpent, gd_newman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sh_path(G, graph_type):\n",
    "    maxv = 0 \n",
    "    for C in nx.strongly_connected_components(G):\n",
    "        C = G.subgraph(C)\n",
    "        if len(C)>1: # skip one nodes\n",
    "            if nx.average_shortest_path_length(C)>maxv:\n",
    "                maxv = nx.average_shortest_path_length(C)\n",
    "    return maxv \n",
    "\n",
    "avg_ours = avg_sh_path(G_ours, 'Ours')\n",
    "avg_saito = avg_sh_path(G_saito, 'Saito')\n",
    "avg_star = avg_sh_path(G_star, 'Star')\n",
    "avg_serpent = avg_sh_path(G_serpent, 'Serpent')\n",
    "avg_newman = avg_sh_path(G_newman, 'Newman')\n",
    "\n",
    "data['Max average shortest path'] = [avg_ours, avg_saito, avg_star, avg_serpent, avg_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Number of connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_cc(G, graph_type):\n",
    "    scc = 0 \n",
    "    wcc = 0 \n",
    "    for C in nx.strongly_connected_components(G):\n",
    "        C = G.subgraph(C)\n",
    "        if len(C)>0: # skip one nodes\n",
    "            scc+=1\n",
    "    for C in nx.weakly_connected_components(G):\n",
    "        C = G.subgraph(C)\n",
    "        if len(C)>1: # skip one nodes\n",
    "            wcc+=1\n",
    "    return scc, wcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 542)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scc_ours, wcc_ours = number_cc(G_ours, 'Ours')\n",
    "scc_ours, wcc_ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_saito, wcc_saito = number_cc(G_saito, 'Saito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_star, wcc_star = number_cc(G_star, 'Star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_serpent, wcc_serpent = number_cc(G_serpent, 'Serpent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_newman, wcc_newman = number_cc(G_newman, 'Newman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Number of scc'] = [scc_ours, scc_saito, scc_star, scc_serpent, scc_newman]\n",
    "data['Number of wcc'] = [wcc_ours, wcc_saito, wcc_star, wcc_serpent, wcc_newman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0, 8, 2, 0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scc_ours, scc_saito, scc_star, scc_serpent, scc_newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153, 1593, 153, 153, 54)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcc_ours, wcc_saito, wcc_star, wcc_serpent, wcc_newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.to_csv('../Results.csv', mode='a', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_analytics(G):\n",
    "    in_deg_centrality = nx.in_degree_centrality(G)\n",
    "    out_deg_centrality = nx.out_degree_centrality(G)\n",
    "    close_centrality = nx.closeness_centrality(G)   \n",
    "    return(max(in_deg_centrality.values()),max(out_deg_centrality.values()), max(close_centrality.values()))\n",
    "\n",
    "# bet_centrality = nx.betweenness_centrality(G, normalized = True, endpoints = False)\n",
    "    # pr = nx.pagerank(G, alpha = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operator\n",
    "# in_deg_centrality = nx.in_degree_centrality(G)\n",
    "# max(in_deg_centrality.items(), key=operator.itemgetter(1))\n",
    "\n",
    "# import operator\n",
    "# out_deg_centrality = nx.out_degree_centrality(G)\n",
    "# max(out_deg_centrality.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(sorted(dict(G.out_degree()).items(), key=lambda item: item[1], reverse=True))\n",
    "# dict(sorted(out_deg_centrality.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.degree(1381900111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Max in degree centrality: 0.005998571768626518\n",
      "-Max out degre centrality: 0.005332063794334682\n",
      "-Max closeness centrality: 0.22641026660105865\n"
     ]
    }
   ],
   "source": [
    "in_d, out_d, close = user_analytics(G_serpent)\n",
    "print('-Max in degree centrality:', in_d)\n",
    "print('-Max out degre centrality:', out_d)\n",
    "print('-Max closeness centrality:', close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
